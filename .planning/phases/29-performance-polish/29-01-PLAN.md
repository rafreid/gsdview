---
phase: 29-performance-polish
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/renderer/renderer.js
autonomous: true

must_haves:
  truths:
    - "50+ rapid file operations animate smoothly without stuttering"
    - "Animation frame rate stays at 60fps during operation bursts"
    - "Individual flashes remain visible even when batched"
  artifacts:
    - path: "src/renderer/renderer.js"
      provides: "Animation batching system for rapid operations"
      contains: "MAX_CONCURRENT_FLASHES"
  key_links:
    - from: "flashNodeWithType"
      to: "pendingFlashes queue"
      via: "queue overflow handling"
      pattern: "pendingFlashes|MAX_CONCURRENT"
---

<objective>
Add animation batching to handle rapid successive operations (50+ files) smoothly

Purpose: When git commits or large refactors trigger many file operations, the current system spawns individual RAF loops for each flash, potentially overwhelming the animation system and dropping frames. This plan adds a batching mechanism to limit concurrent animations.

Output: Modified flashNodeWithType that queues excess animations and processes them in waves
</objective>

<execution_context>
@/home/rafreid/.claude/get-shit-done/workflows/execute-plan.md
@/home/rafreid/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/28-enhanced-flash-effects/28-01-SUMMARY.md
@src/renderer/renderer.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add animation batching with concurrent flash limit</name>
  <files>src/renderer/renderer.js</files>
  <action>
Add animation batching to limit concurrent flash animations:

1. Add constants near flashingNodes Map:
   ```javascript
   const MAX_CONCURRENT_FLASHES = 20; // Limit concurrent animations
   const pendingFlashes = [];          // Queue for overflow
   ```

2. Modify flashNodeWithType to check concurrent limit:
   - At start of function, check if flashingNodes.size >= MAX_CONCURRENT_FLASHES
   - If at limit, add { nodeId, changeType } to pendingFlashes queue and return early
   - Log when queueing: `[Flash] Queued (${pendingFlashes.length} pending): ${nodeId}`

3. Add processPendingFlashes function:
   ```javascript
   function processPendingFlashes() {
     while (pendingFlashes.length > 0 && flashingNodes.size < MAX_CONCURRENT_FLASHES) {
       const { nodeId, changeType } = pendingFlashes.shift();
       // Re-call flashNodeWithType (it will now have room)
       flashNodeWithType(nodeId, changeType);
     }
   }
   ```

4. Call processPendingFlashes at end of flash animation completion (in the else branch at progress >= 1, after flashingNodes.delete(nodeId))

5. Add cleanup for pendingFlashes when node is deleted:
   - In fadeOutAndRemoveNode, filter pendingFlashes to remove entries for deleted nodeId

Why 20 concurrent limit:
- Each flash runs its own RAF callback
- 20 concurrent animations at 60fps = 1200 material updates/sec
- Above 20, diminishing visual returns (user can't distinguish 30 simultaneous flashes)
- Lower values would batch too aggressively, hiding individual operations
  </action>
  <verify>
1. Read renderer.js and confirm MAX_CONCURRENT_FLASHES constant exists
2. Confirm pendingFlashes array exists
3. Confirm flashNodeWithType checks limit and queues
4. Confirm processPendingFlashes is called after animation completes
5. Search for pendingFlashes in fadeOutAndRemoveNode
  </verify>
  <done>
When flashingNodes.size >= 20, new flash requests queue to pendingFlashes. When existing flashes complete, queued flashes process automatically.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add stagger delay to prevent frame spike on batch processing</name>
  <files>src/renderer/renderer.js</files>
  <action>
Add small stagger delay when processing batched flashes to prevent frame spike:

1. Modify processPendingFlashes to use setTimeout for staggered processing:
   ```javascript
   function processPendingFlashes() {
     if (pendingFlashes.length === 0) return;
     if (flashingNodes.size >= MAX_CONCURRENT_FLASHES) return;

     const { nodeId, changeType } = pendingFlashes.shift();
     flashNodeWithType(nodeId, changeType);

     // Stagger next batch item by 50ms to prevent frame spike
     if (pendingFlashes.length > 0) {
       setTimeout(processPendingFlashes, 50);
     }
   }
   ```

2. Update the call site in flashNodeWithType completion:
   - Instead of calling processPendingFlashes directly, use:
   ```javascript
   if (pendingFlashes.length > 0) {
     setTimeout(processPendingFlashes, 50);
   }
   ```

Why 50ms stagger:
- At 60fps, 50ms = 3 frames between new animation starts
- Prevents all 20 slots from trying to start simultaneously
- Still processes 20 queued items per second (fast enough for user perception)
  </action>
  <verify>
1. Read renderer.js and confirm processPendingFlashes uses setTimeout
2. Confirm stagger delay is 50ms
3. Verify setTimeout call in flashNodeWithType completion branch
  </verify>
  <done>
Queued flash animations start with 50ms stagger delay, preventing frame spikes when processing large batches.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add batch statistics logging for debugging</name>
  <files>src/renderer/renderer.js</files>
  <action>
Add console logging to help debug batching behavior:

1. When queueing a flash (in the early return path):
   ```javascript
   console.log('[Flash] Queued (active:', flashingNodes.size, 'pending:', pendingFlashes.length, '):', nodeId);
   ```

2. When processing from queue (in processPendingFlashes):
   ```javascript
   console.log('[Flash] Processing from queue (remaining:', pendingFlashes.length, '):', nodeId);
   ```

3. Add a one-time log when queue is fully drained:
   ```javascript
   if (pendingFlashes.length === 0) {
     console.log('[Flash] Queue drained, all animations complete');
   }
   ```

This provides visibility into batching behavior during operation bursts without requiring a separate debug panel.
  </action>
  <verify>
1. Read renderer.js and confirm queueing log message exists
2. Confirm processing from queue log message exists
3. Confirm queue drained log message exists
4. Run app, trigger rapid file operations, check DevTools console for batch logs
  </verify>
  <done>
Console shows batching activity: when flashes are queued, when they process from queue, and when queue drains.
  </done>
</task>

</tasks>

<verification>
1. Open GSD Viewer and monitor DevTools console
2. Trigger rapid file operations (e.g., `git checkout -- .` to restore many files)
3. Observe:
   - Flash animations play smoothly without stuttering
   - Console shows queuing when > 20 simultaneous operations
   - Console shows queue processing as slots free up
   - All queued files eventually flash (none lost)
4. Verify frame rate stays smooth (no visible jank)
</verification>

<success_criteria>
- [ ] MAX_CONCURRENT_FLASHES = 20 limits simultaneous animations
- [ ] pendingFlashes queue stores overflow operations
- [ ] processPendingFlashes drains queue with 50ms stagger
- [ ] Console logs show batching activity for debugging
- [ ] Deleted nodes cleaned from pending queue
- [ ] FLX-07 requirement satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/29-performance-polish/29-01-SUMMARY.md`
</output>
